#Tensor product hilbert space dimension: 4; Number of simulations: 100;
#Separable DMs were read from: /content/drive/MyDrive/Fisymat/TFM/code/entanglement_2x2/input_data/mixed_states/mixed_separable.txt; Entangled DMs were read from: /content/drive/MyDrive/Fisymat/TFM/code/entanglement_2x2/input_data/mixed_states/mixed_entangled.txt;
#Architecture of the MLP: [8, 4, 1]; Number of epochs: 200; Fraction of DMs used for training: 0.8;
#Activation function in the hidden layers: sigmoid; Activation function in the output layer: sigmoid; Loss function: binary_crossentropy;
#Batch size: 40; Test tolerance: 0.05; DMs were read with redundancy: False;
#Sucess rate averaged over every simulation and over every sample in the test set: 99.79375%
#Sample standard deviation for averaged success rate: 0.0073859690656582905%
#Epoch	Loss	Sample STD
1	0.703613	0.021264
2	0.693230	0.000103
3	0.693122	0.000227
4	0.692959	0.000569
5	0.692674	0.001430
6	0.692067	0.003593
7	0.690796	0.008071
8	0.688423	0.015642
9	0.684587	0.026083
10	0.678865	0.039031
11	0.670842	0.054611
12	0.660331	0.072715
13	0.647685	0.092023
14	0.633498	0.110661
15	0.618221	0.127573
16	0.601833	0.142643
17	0.584234	0.156053
18	0.565436	0.167994
19	0.545646	0.178615
20	0.525276	0.187982
21	0.504698	0.195939
22	0.483752	0.202413
23	0.462640	0.207621
24	0.441125	0.211820
25	0.419617	0.215115
26	0.398445	0.217574
27	0.377801	0.219016
28	0.357940	0.219223
29	0.338858	0.218130
30	0.320563	0.215870
31	0.302908	0.212737
32	0.286038	0.209228
33	0.270086	0.205608
34	0.255190	0.201992
35	0.241509	0.198550
36	0.229086	0.195239
37	0.217840	0.191990
38	0.207589	0.188629
39	0.198088	0.185069
40	0.189244	0.181323
41	0.180932	0.177479
42	0.173112	0.173540
43	0.165746	0.169562
44	0.158720	0.165407
45	0.151969	0.161030
46	0.145497	0.156390
47	0.139174	0.151544
48	0.133018	0.146490
49	0.127064	0.141347
50	0.121249	0.136104
51	0.115622	0.130796
52	0.110133	0.125548
53	0.104833	0.120307
54	0.099668	0.115140
55	0.094657	0.110035
56	0.089823	0.105042
57	0.085123	0.100125
58	0.080571	0.095316
59	0.076148	0.090614
60	0.071941	0.086113
61	0.067897	0.081795
62	0.064050	0.077630
63	0.060407	0.073694
64	0.056955	0.069932
65	0.053723	0.066371
66	0.050679	0.062968
67	0.047807	0.059749
68	0.045144	0.056677
69	0.042619	0.053745
70	0.040252	0.050998
71	0.038033	0.048399
72	0.035951	0.045947
73	0.033995	0.043639
74	0.032190	0.041491
75	0.030478	0.039448
76	0.028867	0.037548
77	0.027372	0.035746
78	0.025978	0.034062
79	0.024636	0.032418
80	0.023397	0.030893
81	0.022219	0.029406
82	0.021124	0.028009
83	0.020089	0.026662
84	0.019092	0.025378
85	0.018159	0.024137
86	0.017282	0.023009
87	0.016459	0.021931
88	0.015680	0.020949
89	0.014959	0.020037
90	0.014280	0.019219
91	0.013662	0.018460
92	0.013072	0.017757
93	0.012528	0.017100
94	0.012030	0.016513
95	0.011563	0.015952
96	0.011115	0.015454
97	0.010708	0.014971
98	0.010319	0.014533
99	0.009985	0.014158
100	0.009646	0.013793
101	0.009342	0.013471
102	0.009057	0.013192
103	0.008785	0.012904
104	0.008535	0.012666
105	0.008306	0.012440
106	0.008078	0.012227
107	0.007873	0.012022
108	0.007677	0.011831
109	0.007472	0.011651
110	0.007311	0.011499
111	0.007140	0.011330
112	0.006968	0.011163
113	0.006821	0.011031
114	0.006682	0.010882
115	0.006526	0.010727
116	0.006405	0.010618
117	0.006276	0.010481
118	0.006149	0.010341
119	0.006030	0.010225
120	0.005910	0.010114
121	0.005804	0.009987
122	0.005695	0.009881
123	0.005595	0.009773
124	0.005504	0.009679
125	0.005401	0.009564
126	0.005313	0.009458
127	0.005214	0.009346
128	0.005141	0.009275
129	0.005063	0.009189
130	0.004986	0.009095
131	0.004897	0.009004
132	0.004821	0.008914
133	0.004744	0.008826
134	0.004672	0.008750
135	0.004605	0.008654
136	0.004544	0.008583
137	0.004469	0.008498
138	0.004401	0.008430
139	0.004348	0.008349
140	0.004296	0.008285
141	0.004232	0.008217
142	0.004179	0.008154
143	0.004114	0.008080
144	0.004064	0.008013
145	0.004002	0.007949
146	0.003965	0.007901
147	0.003921	0.007832
148	0.003866	0.007787
149	0.003819	0.007730
150	0.003773	0.007665
151	0.003722	0.007593
152	0.003692	0.007572
153	0.003649	0.007512
154	0.003599	0.007467
155	0.003558	0.007423
156	0.003528	0.007336
157	0.003483	0.007335
158	0.003453	0.007296
159	0.003404	0.007218
160	0.003375	0.007199
161	0.003333	0.007163
162	0.003296	0.007115
163	0.003269	0.007071
164	0.003244	0.007040
165	0.003201	0.007007
166	0.003177	0.006965
167	0.003137	0.006930
168	0.003112	0.006907
169	0.003084	0.006875
170	0.003055	0.006828
171	0.003031	0.006816
172	0.002994	0.006784
173	0.002982	0.006751
174	0.002946	0.006725
175	0.002907	0.006687
176	0.002894	0.006661
177	0.002868	0.006622
178	0.002849	0.006611
179	0.002813	0.006569
180	0.002795	0.006542
181	0.002773	0.006510
182	0.002748	0.006484
183	0.002734	0.006468
184	0.002705	0.006443
185	0.002677	0.006410
186	0.002667	0.006391
187	0.002641	0.006360
188	0.002624	0.006338
189	0.002603	0.006311
190	0.002576	0.006280
191	0.002573	0.006246
192	0.002545	0.006234
193	0.002521	0.006190
194	0.002508	0.006176
195	0.002481	0.006148
196	0.002469	0.006141
197	0.002456	0.006118
198	0.002440	0.006090
199	0.002417	0.006063
200	0.002402	0.006046
