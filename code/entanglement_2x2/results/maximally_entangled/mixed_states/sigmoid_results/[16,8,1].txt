#Tensor product hilbert space dimension: 4; Number of simulations: 10;
#Separable DMs were read from: /home/julio/Documents/my_projects/TFM/code/entanglement_2x2/input_data/received_from_DM/mixed_states/mixed_separable.txt; Entangled DMs were read from: /home/julio/Documents/my_projects/TFM/code/entanglement_2x2/input_data/received_from_DM/mixed_states/mixed_entangled.txt;
#Architecture of the MLP: [16, 8, 1]; Number of epochs: 151; Fraction of DMs used for training: 0.8;
#Activation function in the hidden layers: sigmoid; Activation function in the output layer: sigmoid; Loss function: binary_crossentropy;
#Batch size: 40; Test tolerance: 0.5; DMs were read with redundancy: False;
#Sucess rate averaged over every simulation and over every sample in the test set: 99.99%
#Sample standard deviation for averaged success rate: 0.004997499374663353%
#Same average success rate for supplementary tests: [0.5001150000000001, 0.500205, 0.5046700000000001, 0.5647, 0.783115, 0.6136, 0.6380349999999999, 0.69631, 0.7941299999999999, 0.884]%
#Sample STD for averaged success rate in supplementary tests: [0.0035334224681956724, 0.00353288450119021, 0.0035048194753795805, 0.003141042104143146, 0.0019608212153967523, 0.0029511357135855337, 0.00285004244507867, 0.0025951241193823468, 0.00203556556145952, 0.0012912203529994398]%
#Epoch	Loss	Sample STD
1	0.703041	0.003840
2	0.693346	0.000048
3	0.693177	0.000063
4	0.693093	0.000135
5	0.692728	0.000341
6	0.691924	0.000956
7	0.690124	0.002483
8	0.686346	0.005780
9	0.679104	0.012100
10	0.668259	0.021354
11	0.656707	0.030218
12	0.645440	0.036597
13	0.632658	0.040937
14	0.615559	0.044579
15	0.593325	0.048498
16	0.567496	0.052901
17	0.538782	0.056844
18	0.507261	0.059616
19	0.473017	0.061872
20	0.439908	0.064042
21	0.410786	0.065699
22	0.385836	0.066556
23	0.363967	0.066699
24	0.344759	0.066343
25	0.327258	0.065419
26	0.311003	0.063902
27	0.294818	0.061759
28	0.278126	0.059311
29	0.261422	0.057301
30	0.245904	0.056067
31	0.231972	0.055303
32	0.219746	0.054671
33	0.208833	0.053962
34	0.198848	0.053177
35	0.189549	0.052342
36	0.180970	0.051585
37	0.172929	0.050859
38	0.165398	0.050166
39	0.158297	0.049546
40	0.151501	0.048869
41	0.144708	0.048160
42	0.138218	0.047471
43	0.131835	0.046650
44	0.125512	0.045731
45	0.119140	0.044682
46	0.112765	0.043411
47	0.106134	0.041903
48	0.099436	0.040148
49	0.092577	0.038126
50	0.085566	0.035757
51	0.078430	0.033083
52	0.071231	0.030203
53	0.064068	0.027213
54	0.057007	0.024173
55	0.050425	0.021290
56	0.044146	0.018491
57	0.038237	0.015834
58	0.032816	0.013391
59	0.027990	0.011221
60	0.023764	0.009311
61	0.020065	0.007621
62	0.016895	0.006177
63	0.014281	0.004999
64	0.012062	0.003993
65	0.010282	0.003203
66	0.008851	0.002611
67	0.007687	0.002139
68	0.006707	0.001802
69	0.005930	0.001543
70	0.005354	0.001381
71	0.004806	0.001245
72	0.004364	0.001165
73	0.003994	0.001095
74	0.003668	0.001047
75	0.003384	0.000995
76	0.003130	0.000967
77	0.002962	0.000939
78	0.002765	0.000911
79	0.002585	0.000887
80	0.002432	0.000859
81	0.002309	0.000846
82	0.002164	0.000819
83	0.002049	0.000799
84	0.001930	0.000770
85	0.001840	0.000752
86	0.001782	0.000742
87	0.001697	0.000714
88	0.001614	0.000695
89	0.001539	0.000673
90	0.001488	0.000663
91	0.001454	0.000667
92	0.001377	0.000629
93	0.001309	0.000611
94	0.001260	0.000597
95	0.001204	0.000578
96	0.001172	0.000570
97	0.001114	0.000541
98	0.001071	0.000526
99	0.001040	0.000530
100	0.001012	0.000514
101	0.000970	0.000496
102	0.000948	0.000485
103	0.000897	0.000464
104	0.000876	0.000454
105	0.000844	0.000448
106	0.000830	0.000437
107	0.000780	0.000420
108	0.000778	0.000413
109	0.000741	0.000404
110	0.000717	0.000389
111	0.000701	0.000382
112	0.000655	0.000362
113	0.000657	0.000364
114	0.000637	0.000358
115	0.000607	0.000339
116	0.000597	0.000334
117	0.000591	0.000334
118	0.000570	0.000316
119	0.000549	0.000311
120	0.000536	0.000306
121	0.000524	0.000299
122	0.000502	0.000283
123	0.000485	0.000273
124	0.000483	0.000279
125	0.000471	0.000272
126	0.000455	0.000267
127	0.000459	0.000266
128	0.000425	0.000246
129	0.000425	0.000252
130	0.000422	0.000244
131	0.000405	0.000231
132	0.000403	0.000239
133	0.000394	0.000233
134	0.000379	0.000217
135	0.000367	0.000215
136	0.000344	0.000203
137	0.000357	0.000205
138	0.000342	0.000189
139	0.000324	0.000196
140	0.000323	0.000187
141	0.000319	0.000188
142	0.000308	0.000182
143	0.000293	0.000174
144	0.000299	0.000177
145	0.000293	0.000176
146	0.000287	0.000175
147	0.000295	0.000175
148	0.000275	0.000165
149	0.000262	0.000164
150	0.000246	0.000155
151	0.000258	0.000157
